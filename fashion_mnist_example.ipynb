{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown '1LU5Lcf-wPR9UnOfWNVyXuZRxDQeOzXzX'\n",
        "!unzip 'demo_accessories.zip'"
      ],
      "metadata": {
        "id": "G9wgVD2WV9fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CatcyZUO73Vz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "import utils\n",
        "\n",
        "from sklearn import cluster\n",
        "import os\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "default_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute distinguishability matrices for the channels of a single trained model"
      ],
      "metadata": {
        "id": "jJ5-fjlP-0nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a set of images to be used for the distinguishability matrix\n",
        "dataset_name = 'fashion_mnist'\n",
        "number_standard_candle_examples = 300\n",
        "dset, dset_info = tfds.load(dataset_name, with_info=True, decoders={\n",
        "        'image': tfds.decode.SkipDecoding()})\n",
        "dset = dset['train']\n",
        "\n",
        "dset = dset.map(lambda example: (example['image'], example['label']))\n",
        "\n",
        "dset = dset.shuffle(1_000_000)  ## shuffle everything before the image decoding\n",
        "\n",
        "dset = dset.map(\n",
        "  lambda image, label: (dset_info.features['image'].decode_example(image), label))\n",
        "dset = dset.map(lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label))\n",
        "\n",
        "standard_candle_images, standard_candle_labels = next(iter(dset.batch(number_standard_candle_examples)))"
      ],
      "metadata": {
        "id": "XlxE6oRw7_if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'trained_fashion_mnist_beta4/'\n",
        "print(f'Loading {model_dir}')\n",
        "number_bottleneck_channels = 10\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "image_side = 28\n",
        "image_channels = standard_candle_images.shape[-1]\n",
        "encoder = tf.keras.Sequential(\n",
        "  [\n",
        "  tfkl.Input((image_side, image_side, image_channels)),\n",
        "  tf.keras.layers.Conv2D(32, 4, strides=2, activation='relu', padding='same'),\n",
        "  tf.keras.layers.Conv2D(64, 4, strides=2, activation='relu', padding='same'),\n",
        "  tfkl.Flatten(),\n",
        "  tfkl.Dense(256, 'relu'),\n",
        "  tfkl.Dense(2*number_bottleneck_channels)\n",
        "  ])\n",
        "\n",
        "decoder = tf.keras.Sequential(\n",
        "  [\n",
        "  tf.keras.Input((number_bottleneck_channels,)),\n",
        "  tfkl.Dense(7*7*32, 'relu'),\n",
        "  tfkl.Reshape([7, 7, 32]),\n",
        "  tfkl.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n",
        "  tfkl.Conv2DTranspose(32, 4, strides=2, padding='same', activation='relu'),\n",
        "  tfkl.Conv2DTranspose(image_channels, 4, padding='same')\n",
        "  ])\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(step=tf.Variable(0), encoder=encoder, decoder=decoder)\n",
        "checkpoint_directory = os.path.join(model_dir, \"training_checkpoints\")\n",
        "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
        "checkpoint_ind = 1\n",
        "checkpoint.restore(os.path.join(checkpoint_directory, f'ckpt-{checkpoint_ind}')).expect_partial()\n",
        "\n",
        "## Run a sample through the model to check that it was restored properly\n",
        "embs = encoder(standard_candle_images[:10])\n",
        "mus, logvars = tf.split(embs, 2, -1)\n",
        "reparam = tf.random.normal(mus.shape, mus, tf.exp(logvars/2.))\n",
        "recon = decoder(reparam)\n",
        "plt.figure(figsize=(10, 2))\n",
        "for img_ind in range(10):\n",
        "  plt.subplot(2, 10, 1+img_ind)\n",
        "  plt.imshow(standard_candle_images[img_ind])\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(2, 10, 11+img_ind)\n",
        "  plt.imshow(tf.nn.sigmoid(recon[img_ind]))\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LnsWQxhd9WTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute the distinguishability matrices for the model's 10 channels and visualize them\n",
        "inches_per_subplot = 2\n",
        "plt.figure(figsize=(inches_per_subplot*number_bottleneck_channels, inches_per_subplot))\n",
        "standard_candle_embs = encoder(standard_candle_images)\n",
        "embs_mus, embs_logvars = tf.split(standard_candle_embs, 2, -1)\n",
        "for channel_id in range(number_bottleneck_channels):\n",
        "  bhat_distance_mat = utils.bhattacharyya_dist_mat(np.reshape(embs_mus[:, channel_id], [number_standard_candle_examples, 1]),\n",
        "                                          np.reshape(embs_logvars[:, channel_id], [number_standard_candle_examples, 1]))\n",
        "\n",
        "  plt.subplot(1, number_bottleneck_channels, channel_id+1)\n",
        "  plt.imshow(np.exp(-bhat_distance_mat)[:100, :100], vmin=0, vmax=1)\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  plt.xlabel(f'Channel {channel_id}', fontsize=14)\n",
        "\n",
        "plt.suptitle('Bhattacharyya distinguishability matrices for each channel', y=0.95, fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBv6_5Ts-Ald"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute pairwise NMI and VI values given a set of distinguishability matrices, assess structure"
      ],
      "metadata": {
        "id": "9hBuQYqs-4Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load precomputed distinguishability matrices; the last one is the matrix for the class label\n",
        "bhat_distance_mats = np.load('bhats.npy')\n",
        "bhats_labels = bhat_distance_mats[-1:]  ## these were stored simply as a distinguishability mat with 0s and 1s\n",
        "bhats_labels_distances = -np.log(np.clip(bhats_labels, 1e-8, None))\n",
        "bhat_distance_mats = np.concatenate([bhat_distance_mats[:-1], bhats_labels_distances], 0)\n",
        "print(f'Distinguishability matrices shape: {bhat_distance_mats.shape}')\n",
        "\n",
        "print('Computing pairwise similarity between the channels')\n",
        "pairwise_nmi, pairwise_vi = utils.compute_pairwise_similarities(bhat_distance_mats)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for plt_ind, (pairwise_mat, label) in enumerate(zip([pairwise_nmi, pairwise_vi],\n",
        "                                                    ['NMI', 'VI'])):\n",
        "  plt.subplot(1, 2, plt_ind+1)\n",
        "  plt.imshow(pairwise_mat)\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  plt.title(label, fontsize=16)\n",
        "  plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "isoy5ziA-w_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPTICS_MIN_SAMPLES = 20\n",
        "\n",
        "## Pull off the similarities with the class label\n",
        "nmi_with_labels = pairwise_nmi[-1]\n",
        "vi_with_labels = pairwise_vi[-1]\n",
        "pairwise_nmi = pairwise_nmi[:-1, :-1]\n",
        "pairwise_vi = pairwise_vi[:-1, :-1]\n",
        "\n",
        "for plt_ind, (distance_label, distance_mat, display_mat) in enumerate(zip(['VI', 'NMI'],\n",
        "                                          [np.clip(pairwise_vi, 0, None), -np.log(np.clip(pairwise_nmi, 1e-4, None))],\n",
        "                                          [pairwise_vi, pairwise_nmi])):\n",
        "\n",
        "  clustering = cluster.OPTICS(min_samples=OPTICS_MIN_SAMPLES, metric='precomputed', cluster_method='xi', max_eps=np.inf).fit(distance_mat)\n",
        "  index_reorder = clustering.ordering_\n",
        "  labels = clustering.labels_[index_reorder]\n",
        "  reachability = clustering.reachability_[index_reorder]\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  ax1 = fig.add_axes([0.3, 0.71, 0.6, 0.2])\n",
        "\n",
        "  for cluster_id in np.unique(labels):\n",
        "    Xk = np.arange(distance_mat.shape[0])[labels == cluster_id]\n",
        "    Rk = reachability[labels == cluster_id]\n",
        "    if cluster_id >= 0:\n",
        "      ax1.axvspan(Xk.min(), Xk.max(), color=default_colors[cluster_id%10], alpha=0.6)\n",
        "  ax1.fill_between(np.arange(distance_mat.shape[0]), reachability, color='#454a4a', zorder=100)\n",
        "  ax1.set_xlim(0, len(index_reorder))\n",
        "  ax1.set_ylabel(f'reachability, {distance_label}', fontsize=14)\n",
        "  ax1.set_ylim(0, None)\n",
        "  ax1.set_xticks([])\n",
        "\n",
        "  # Plot the distances to the labels\n",
        "  ax2 = fig.add_axes([0.09, 0.1, 0.2, 0.6])\n",
        "  ax2.plot(nmi_with_labels[index_reorder], range(len(index_reorder)), lw=3)\n",
        "  ax2.set_ylim(0, nmi_with_labels.shape[0])\n",
        "  ax2.set_xlim(0, 1)\n",
        "  ax2.set_xlabel('NMI w class label', fontsize=14)\n",
        "  ax2.invert_xaxis()\n",
        "  ax2.invert_yaxis()\n",
        "  # ax2.set_xticks([])\n",
        "  ax2.set_yticks([])\n",
        "\n",
        "  # Plot distance matrix.\n",
        "  axmatrix = fig.add_axes([0.3, 0.1, 0.6, 0.6])\n",
        "  display_mat_actually = display_mat[index_reorder,:]\n",
        "  display_mat_actually = display_mat_actually[:,index_reorder]\n",
        "  im = axmatrix.imshow(display_mat_actually, aspect='auto', origin='upper', cmap=plt.cm.YlGnBu)\n",
        "  axmatrix.set_xticks([])\n",
        "  axmatrix.set_yticks([])\n",
        "\n",
        "  # Plot colorbar.\n",
        "  axcolor = fig.add_axes([0.91, 0.1, 0.02, 0.6])\n",
        "  cb = plt.colorbar(im, cax=axcolor)\n",
        "  cb.set_label(label=distance_label, fontsize=14)\n",
        "  plt.suptitle('Fashion-MNIST ensemble structure', y=0.94, fontsize=16)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HFhE1Eqc_yOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLNQRMbssOTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}